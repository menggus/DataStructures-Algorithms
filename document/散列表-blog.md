### 散列表

-   散列表是基于数组的一种数据结构，借助于数组随机访问的高效，散列表在随机访问效率是上也是非常的高效，时间复杂度也为O(1)

### 散列表的结构

-   基本结构

    ![](http://im.taolius.com/image/hash-table-1.png)

    图中是一种散列表的结构，还有其他的形式；

    当我们要存储数据时，首先会对数据的key进行 散列函数的计算，将key值映射为数组的下标，然后把数据随机插入数组，这里的随机也就说明了，按顺序插入的数据，而在散列表中存储元素顺序是被打乱了的；

    -   对key进行散列计算的函数，称为 散列函数 （hash函数，哈希函数）
    -   散列函数计算的结果，称为 散列值（hash值，哈希值）

    而得益于数组的随机访问效率，当我们在访问数据时，同样会根据key进行散列计算把key映射为数组下标，再根据下标来访问数据，时间复杂度与数组一样为O(1)

### 散列函数

-   散列函数是重要的，它的效率的高低会影响散列表的相关性能，每一个数据的增删改都会进行散列的计算

-   由于数组下标为非负整数，所以散列函数的计算结果也必须为非负整数

-   对于同一个key散列函数的计算结果应该一样，而对于不同的key散列函数计算的结果不应该一样

    但实际情况是，要符合这一点的散列函数是无法找到的，当前的MD5，SHA，CRC等哈希算法也不能满足，因此对于数组存储数据趋近于数组容量时，会加大散列的冲突。

### 散列冲突

-   什么是散列冲突呢？

    简单理解就是在通过散列函数映射key为数组的下标时，不同的key值映射为相同的数组下标；

-   散列冲突的解决方法

    -   开放寻址法

        核心思想：当出现散列冲突时，就重新寻找一个空闲位置

        -   线性探测：一种简单的寻找空闲位置的方法
    
            ![](http://im.taolius.com/image/hash-table-2.png)
    
            -	当插入数据时，首先进行散列值计算，当计算出的散列值所对应的位置已存在数据，就出现了散列冲突，线性探测会按数组下标顺序便利查找，直到找到空的位置，然后插入数据即可；
            -	当查找数据时，同样进行散列计算，根据散列值对应的位置与查找元素进行比较，如果相等则是目标数据，否则顺序往后遍历查找，直到遍历到空的位置还没找到目标数据，则说明元素不在该散列表中；
            -	删除数据时会有点不同，如果我们查找到数据之后就立即删除，那么该删除位置变为空位。如果下次查找的数据正好在删除位置的后面，当出现散列冲突，遍历查找时，到删除位置就会停止往后查找，而其实数据就在删除位置后一位。所以对于删除数据，并不能真正删除，只能进行记录删除，也就是对删除位置进行**标记**。当遍历到该标记位，还是会继续往后遍历查找；
    
        -   除了线性探测，还有其他的探测空闲位置的方法
    
            -   二次探测
    
                二次探测与线性探测类似，也是往后进行查找，但是查找的步长发生变化，如线性探测是进行位置偏移+1，也就是hash(key)+0，hash(key)+1，hash(key)+2，hash(key)+，而二次探测为hash(key)+0，
    
                hash(key)+1²，hash(key)+2²，hash(key)+3²
    
            -   双重散列
    
                双重散列，其实就是多个散列函数进行散列值的计算，当出现散列冲突就换另一个散列函数进行计算，直到找到无冲突位置
    
        -   开发寻址不可避免的问题
    
            当数组中存储的数据越来越趋近于数组容量时，散列冲突概率会大大提高；为了保证散列表的操作效率，会引入一个**装载因子，装载因子=已装载数据个数/散列表的长度，来保证拥有一定的空闲空间，从而减少散列冲突出现的概率；
    
            装载因子表示了散列表中空闲位置的多少，装载因子越大，说明空闲位置越少。
    
    -   链表法
    
        核心思想：出现散列冲突时，冲突元素插入到散列值对应的链表中，如图绿色为槽位或者桶位；
    
        ![](http://im.taolius.com/image/hash-table-3.png)
    
        -   当插入数据时，同样计算散列值找到对应的槽位，然后把数据插入到槽位对应的链表中，时间复杂度O(1)；
        -   当查询或者删除数据时，同样找到槽位，然后遍历，查找数据，对应的时间复杂度为链表的时间复杂度，如果数据是均匀分布时，每个链表的元素个数为k=n/m（n为元素个数，m为槽位数），所以对于的时间复杂度为O(k)，与链表的长度成正比；

### 散列表的设计

​	散列表的设计主要涉及散列函数的设计、装载因子、散列冲突等相关的处理，每一点都会影响散列表的性能；例如散列函数太复杂，那计算起来就会耗时；如果装载因子过大，那么会更容易出现散列冲突，散列冲突概率上升，散列表的操作效率就会下降等；

-   散列函数的设计

    -   散列函数不能太复杂，太复杂的散列函数，会花费更多的计算时间
    -   散列函数生成的值尽可能的随机并分布均匀，减少散列冲突，就算出现冲突情况，也不会某个槽内数据分布多，而降低查询效率

-   设定合理的装载因子

    装载因子会随着填入散列表中的元素的增加而变大， 装载因子越大，散列冲突的概率就越大；

    -   静态数据，对于很少频繁更新数据的散列表，我们可以根据数据的分布，规律找到合理的散列函数，来使得散列值随机分布以及更均匀

    -   动态数据，对于更新频繁插入、删除的散列表，由于数据是未知的，我们无法事先申请一个足够大的容量，所以就需要使用到**动态扩容**，当散列表数据增加，装载因子越来越大，带来了高概率的散列冲突，我们可以通过动态扩容来使得散列表容量增大，而增加空闲空间。

        例如，原来的散列表的装载因子达到了0.8，当我们给散列表的容量增加一倍，那装载因子就变为了0.4；

    -   动态扩容的效率提升

        只要出现动态扩容，就涉及数据的搬移，而数据搬移是非常耗时的；它涉及到重新计算散列值，以及数据的移动，特别是集中性的搬移数据，会使得插入数据非常的耗时。

        怎么实现高效率的动态扩容呢？

        当装载因子达到阈值，我们重新申请一个新空间，但不立即搬移老的数据。当有新的数据插入时，我们将新数据插入到新空间中，并从老的散列表中拿取一个数据插入到新的空间，这样随着插入数据的进行，老的数据就慢慢移动到了新空间，而不会出现在某个集中搬移数据时的操作非常耗时；

    -   有动态扩容，就会有缩容
    
        这是对内存空间比较敏感时，当随着删除操作，散列表中的元素越来越少，没有必要占用更大的容量空间，所以设定一个缩小散列表容量的机制，当装载因子少于一定值时，进行缩容的操作；
    
-   选择合理的散列冲突解决方法

    -   开放寻址
        -   优点:  数据存储在数组中，可以利用cpu的缓存机制，提高查询效率；序列化起来比较简单，不像链表法还包含指针，序列化起来相对麻烦；
        -   缺点：删除数据时，不能真正的删除，只能标记删除；数据存储在一个数组中，相对于链表法，冲突的代价更高，装载因子设定不能太大（太小，空闲空间多），所以相对于链表法，会浪费更多的内存空间；
        -   小结：当数据量比较小时、装载因子小的时候，更适合采用开放寻址法。
    -   链表法
        -   优点：内存利用率更高；对装载因子的容忍度更高，开放寻址的装载因子只能使用与小于1的情况，而链表法可以更大，只要数据分布均匀，本质上也就是槽位对应的链表长度增加，查询效率虽然有下降，但还是比起顺序查找更快
        -   缺点：链表法存储数据需要使用链表，而链表相对数组，内存的占用会更高，比较耗内存；而且不能利用cpu缓存提高操作效率；
        -   注意点：如果链表存储的数据对象很大， 那么对于链表法中链表指针占用内存就可以忽略；如果不适用链表，而使用其他的跳表，红黑树来替代链表法中的链表，就算数据全部在一个槽位内，查询时间复杂度也就退化到O(logn)
        -   小结：基于链表法的散列冲突处理方式比较适合存储大对象，大数据的散了表；

-   散列表设计举例分析(Java中的数据结构HashMap)

    -   初始大小的设定：默认位16，且默认值可根据实际数据多少重新设定，而减少动态扩容次数；
    -   装载因子的设定：最大装载因子位0.75，超过就会动态扩容，每次扩容位原来2倍；
    -   散列冲突解决方式：链表法，但会出现链表长度过长的问题，所以引入红黑树，当链表长度超过一定长度，链表就会转化位红黑树；当红黑树的节点个数少于一定数量时，又会将红黑树转换位链表；因为数据较少时，红黑树要维护平衡，比起链表来， 性能上的优势并不明显；
    -   散列函数设计 (可看源码)

-   散列设计要求总结

    -   支持快速的查询、插入、删除操作
    -   内存占用合理，不浪费过多的内存空间
    -   性能稳定，极端情况也不会退化到无法接受情况

-   散列表设计总结

    -   设计合适的散列函数
    -   定义合理的装载因子，以及合理的动态扩容机制
    -   选择合适的散列冲突解决办法

### 哈希算法的应用

-   安全加密

    例如：常用的加密算法MD5（MD5 Message-Digest Algorithm， MD5消息摘要算法）和SHA（Secure Hash Algorithm 安全散列算法）

    对于安全加密算法重要注意：

    -   很难根据哈希值反向推导出原始值
    -   散列冲突的概率要很小

-   唯一标识

    假设我们现在需要在100万个图片中查找一张图片是否存在，第一我们不能使用原始信息来进行对比，例如使用图片名称，因为可能存在相同名称的图片；第二我们可以使用原始图片二进制，全数据对比，但是这样每次对比时的数据比对量相对较大，相对耗时；

    我们可以对图片获取一个唯一的标识来进行辨别，例如可以对图片的前100字节，中间100字节，后100字节，一起300字节通过哈希算法取哈希值，将这个哈希值作为图片的唯一标识，之后通过唯一标识来进行查找；

    如果把所有图片的存储路径存储在对应唯一标识的散列表中，将更加有效率的查找图片和查看图片的存储路径；

    当插入一张图片时，首先查看是否在散列表中，如果不存在则直接对图片进行散列计算，添加到散列表中；

    如果图片存在，则通过图片的路径找到图片，并做全量对比，看是否是一张图片，如果是同一张图片则不作操作，如果不是同一张图片，也就是说出现散列冲突，唯一标识一样，但并不是同一张图片；

-   数据校验

    我们经常在下载大文件时，经常看到MD5校验值，这就是对原始下载文件去MD5算法的值，当我们在下载过程中可能会出现一些网络问题，或者说下载文件出现错误，数据校验就是通过哈希算法来保证下载之后的文件与原始文件一样，这也是得益于哈希算法对数据的敏感性，只要有一点点的改变，哈希算法求出的值也会不一样；

-   散列函数

    散列函数是设计散列表时很重要的一点，这也是哈希算法的一个重要的且经常使用的应用；

    哈希算法在散列函数中的应用更加注重：

    -   对是否可以反向推导并不关系，对散列冲突的容忍性要好与其他哈希算法
    -   更加关注计算出的散列值是否均匀分布和散列函数计算执行快慢

-   负载均衡

    如何实现一个**会话粘滞**的负载均衡算法？我们需要在同一个客户端上，在一次会话中的所有请求都路由到同一台服务器上。

    简单的实现方法就是：维护一个映射关系，把ip地址或者会话ID与服务器编号构建映射关系，客户端发出的请求，都先在映射表中查找对于的服务器编号，然后再请求对应的服务器。存在弊端：

    -   如果客户端很多，则映射表可能很大，浪费内存空间；
    -   客户端下线/上线，服务器扩容/缩容都会导致映射关系的失效，维护成本大；

    另一种实现方式：我们通过客户端IP地址或者会话ID计算哈希值，将取得的哈希值与服务器的大小进行取模运算，最终得到的值就是被路由到的服务器编号；

-   数据分片

    例1：有较大的日志文件2T，里面记录了用户的搜索关键词你，我们想要快速统计出每个关键词被搜索的次数，该怎么做？

    问题点：

    -   日志文件很大，不能一次性读取进一台机器的内存；
    -   只使用一台机器，处理时间会比较耗时；

    对于上述问题，我们引入**数据分片**，并将分片数据放到多台机器进行处理

    -   首先从日志文件中读取数据，依次读取每个搜索关键词，然后对关键词进行哈希算法的计算，计算结果对n（处理机器台数）取模，最终得到的值就是应该分配到的机器编号。
    -   哈希值相同关键词就会被分配到同一机器，每个机器分别计算出关键词的出现次数，最后对所有机器的结果进行合并即可

    例2：假设现在有1亿张图片，如何判断图片是否在这1亿张图片中？

    问题点：

    -   判断图片是否在图库中，通常使用图片的唯一标识来进行判断，但是如果图片过大，构建散列表时就会出现问题，单机的内存不够使用的问题；

    上述问题，可通过对数据进行分片，通过n台机器，每一台机器维护一部分图片的散列表；每次从图库中读取一个图片并计算唯一标识，然后通过唯一标识对n进行取模，得到结果就是维护该图片所有散列表的机器编号，然后将这个图片的唯一标识和存储路径发送到对应机器的构建散列表；

    当要判断一个图片是否存在时，首先对图片进行唯一标识的计算，然后对n取模，得到处理的机器编号，然后去对应编号的机器的散列表进行查找；

    小结：上述例子均是通过采用多台机器进行处理，来突破单机的限制的问题，也就是哈希算法在数据分片的应用；

-   分布式存储

    当前互联网数据时往往是海量的数据，对于单机的处理能力的上限，为了能提高数据的读取与写入能力，就引入了分布式的方式来存储数据，比如分布式缓存等等；

    问题：

    -   怎么判断数据该存储到那台机器呢？

    根据前面的思想，首先计算数据的哈希值，然后对n台机器取模，这个得到的结果就是应该存储的机器编号；

    但是，如果n出现变化，也就是可能机器数量不够存储了，需要扩容，n就会变大，那么会出现之前存储的值就会需要重新计算的问题；对应的类似于缓存出现失效，那么所有请求就会穿透缓存，直接请求数据库，就可能发生雪崩效应，造成数据库的崩溃；

    问题：

    -   怎么在新加入机器的情况下，不需要重新计算，
    -   也不需要做大量数据的搬移

    **一致性哈希算法**：

    ​	假设我们有n台机器，数据的哈希值范围时[0，Max]，我们将整个范围划分为m个小区间（m远大于n），每个机器负责m/n个小区间，当有新机器加入时，我们将某几个小区间的数据，从原来的机器中搬移到新机器中，这样就不需要重新计算哈希，大量数据搬移，也保持了各个机器上数据数量的均衡。

    